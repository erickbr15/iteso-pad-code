{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<img src=\"./Imagenes/ITESO_Logo.png\" style=\"width:500px;height:142px;\" title=\"Logo ITESO\">\n",
    "<br><font face = \"Times New Roman\" size = \"6\"><b><center>Maestría en Sistemas Computacionales</center></b></font>\n",
    "<br><font face = \"Times New Roman\" size = \"5\"><b><center>Programación para Análisis de Datos</center></b></font>\n",
    "\n",
    "<b><br><font face = \"Times New Roman\" size = \"4\"><center>Unidad 5: Proceso de Selección de Métodos</center></font>\n",
    "<font face = \"Times New Roman\" size = \"4\"><center>Tema 5.1: Procesamiento de Lenguaje Natural</center></font>\n",
    "<font face = \"Times New Roman\" size = \"4\"><center>Subtema a: Conteo de Texto</center></font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESAMIENTO DE LENGUAJE NATURAL\n",
    "\n",
    "De acuerdo con las últimas estadísticas del mercado, la creación de datos se está acelerando. Un [informe de la empresa Seagate y la consultora IDC](https://www.seagate.com/files/www-content/our-story/trends/files/idc-seagate-dataage-whitepaper.pdf) concluye que para el año 2025 se habrán creado más de 175 ZB de datos en el mundo, un dato que será 5 veces superior al registrado en 2019. El 79% de estos datos están en formato texto, de ahí que el llamado **Procesamiento del Lenguaje Natural (PLN)**, o mejor conocido como **NLP** por sus siglas en inglés (***Natural Languaje Processing***), este tomando tanta importancia y se perciba como elemento clave en la gestión de datos del futuro más cercano.\n",
    "\n",
    "El **NLP** es la práctica del entendimiento de cómo las personas organizan los pensamientos, sentimientos, lenguaje y comportamiento. Un campo que se extiende hasta las ciencias de la computación, inteligencia artificial y lingüística en el estudio de las interacciones entre las computadoras y los seres humanos. El objetivo es poder dotar a la máquina de la capacidad de interpretar el texto simulando la habilidad humana de entender el lenguaje. \n",
    "\n",
    "El **NLP** trata de reconocer patrones y de interpretar cadenas de texto para analizar de forma efectiva grandes volúmenes de datos. Permite filtrar y descubrir nuevos elementos dentro de la información a la que nos enfrentamos en una estrategia de datos, pudiendo centrarnos así en el ***SmartData*** más que en el ***BigData***. \n",
    "\n",
    "Los Sistemas basados en **NLP** han permitido grandes innovaciones como el buscador de **Google**, el asistente de voz de **Amazon** (*Alexa*) o de **Apple** (*Siri*), o el sistema de recomendación de **Spotify** ([este artículo explica la manera como Spotify emplea técnicas de PLN](https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe)).\n",
    "\n",
    "Esta práctica se postula como un factor determinante en el sector por su potencial para eliminar las barreras de entrada hacia la industria de los datos y la **Inteligencia de Negocios** (**BI**, por sus siglas en inglés, ***Business Intelligence***), haciéndolo más amigable con el usuario. En un futuro cercano, perfiles menos técnicos podrían interactuar con asistentes inteligentes y realizar tareas de **BI** desde una plataforma conversacional. Esto acercaría la disciplina a perfiles de negocio y animaría a los desconfiados a probar estrategias de **BI** avanzado, favoreciendo así la prueba e integración de estrategias de datos en el núcleo de negocio de las empresas.\n",
    "\n",
    "### Conclusión:\n",
    "El **NLP** es un campo dentro de la inteligencia artificial y la lingüística aplicada que estudia las interacciones mediante uso del lenguaje natural entre los seres humanos y las máquinas. Más concretamente se centra en el procesamiento de las comunicaciones humanas, dividiéndolas en partes, e identificando los elementos más relevantes del mensaje. Con la comprensión y generación de Lenguaje Natural, se busca que las máquinas consigan entender, interpretar y manipular el lenguaje humano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicaciones del NLP\n",
    "\n",
    "El **NLP** se utiliza actualmente en diferentes áreas y para distintas funciones, como por ejemplo:\n",
    "\n",
    "#### a) Comprensión del Lenguaje Natural\n",
    "La **Comprensión del Lenguaje Natural (CLN)** o **NLU** (por sus siglas en inglés, ***Natural Languaje Understanding***) se encarga de interpretar un mensaje y entender su significado e intención, tal y como haría una persona. Para que el sistema funcione necesita grupos de datos en el idioma específico, así como las reglas de gramática, teoría semántica y pragmática (para entender el contexto e intencionalidad), entre otros.\n",
    "\n",
    "#### b) Generación del Lenguaje Natural\n",
    "La **Generación del Lenguaje Natural (GLN)** o **NLG** (por sus siglas en inglés, ***Natural Languaje Generation***) dota a la máquina de la capacidad de crear un nuevo mensaje en lenguaje humano de manera autónoma. De manera resumida, lo que hacen estos modelos es seleccionar la información a reproducir (dependiendo de la interpretación del mensaje a contestar), así como decidir la manera de organizarla y de reproducirla (léxico y recursos gramaticales, morfología, estructuras sintácticas, entre otros). Estos modelos generan frases nuevas palabra a palabra y tienen que ser entrenados para que funcionen correctamente.\n",
    "\n",
    "#### c) Recuperación de Información\n",
    "La **Recuperación de Información (RI)** o **IR** (por sus siglas en inglés, ***Information Retrieval***) es el campo dentro de la informática que se encarga de procesar textos de documentos para poder recuperar partes específicas en base a palabras clave. Por ejemplo, técnicas como la extracción de información estructurada (que permite obtener de un documento una porción de texto en el que se encuentra el contenido buscado) o los sistemas de respuesta a preguntas de usuarios (que devuelve ante una consulta, una respuesta de un banco de respuestas ya existentes, las cuales están asociadas a palabras clave de la consulta).\n",
    "\n",
    "#### d) Reconocimiento y Síntesis del Habla\n",
    "El **Reconocimiento y Síntesis del Habla** son sistemas que procesan los mensajes de voz humana, los transforman en texto, los interpretan y comprenden la intencionalidad de los mismos. Adicional a ello y tras la generación de la respuesta en texto, se vuelve a transformar en voz humana a través de la síntesis de voz. La síntesis del habla o de voz es la que capacita a la máquina para poder generar y reproducir habla en lenguaje natural.\n",
    "\n",
    "#### e) Traducción Automática\n",
    "La **Traducción Automática** o ***Machine Translation*** es un campo de investigación dentro de la lingüística computacional que estudia los sistemas capaces de traducir mensajes entre diferentes lenguas o idiomas. Por ejemplo **Google** es una de las empresas que más ha invertido en sistemas de traducción automática, con su traductor que utiliza un motor estadístico propio. Los sistemas de autocorrección y autocompletado de texto también utilizan **Procesamiento del Lenguaje Natural**.\n",
    "\n",
    "#### f) Resumen y Clasificación de Textos\n",
    "También se está utilizando el **Procesamiento del Lenguaje Natural** para resumir textos de extensiones largas de manera automática o extraer palabras clave para clasificarlos. Muchas veces y debido a la gran cantidad de documentación o por la longitud de la misma, utilizar estos sistemas ayuda en sectores como el legal a encontrar partes dentro de las leyes, o resumir una gran cantidad de documentación. Otro de los usos que se le da a esta función de clasificación es la de detección de *spam* o correos malintencionados. Empresas como **Google** utilizan esta tecnología para clasificar los textos de los correos electrónicos y detectar si se trata de *spam* o no. Para esto, toman palabras clave como “*gratis*” o “*descuento*”, la condición de palabras en mayúsculas o las exclamaciones.\n",
    "\n",
    "#### g) Detección de Sentimientos o Emociones\n",
    "Uno de los usos más novedosos del **NLP** es el análisis de sentimientos. Cada vez más empresas y profesionales del marketing están utilizando esta tecnología para saber lo que sienten los usuarios sobre una marca, producto o servicio, utilizando datos de entrada como mensajes, comentarios o reacciones en diferentes redes sociales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar las operaciones del **Procesamiento de Lenguaje Natural** en **Python** se empleará la librería **Natural Languaje ToolKit (NLTK)**.\n",
    "\n",
    "#### La Librería NLTK\n",
    "<br>\n",
    "<img src=\"./Imagenes/nltk_logo.png\" style=\"width:525px;height:200px;\" class=\"center\">\n",
    "<br>\n",
    "\n",
    "La librería de software **NLTK** es una plataforma líder para el procesaminto de datos de lenguaje humano, al proporcionar una interfaz de fácil uso con más de 50 colecciones de corpus y léxicos (por ejemplo, ***WordNet***) junto con librerías de procesamiento de texto para clasificación, tokenización, derivación, etiquetado, análisis y razonamiento semántico.\n",
    "\n",
    "La librería **NLTK** y su documentación se pueden consultar a través de [esta liga](https://www.nltk.org) para su versión 3.5 que es la más reciente.\n",
    "\n",
    "Para importar la librería se empleará la función:\n",
    "```python\n",
    "import nltk\n",
    "```\n",
    "A partir de ello se podrá hacer uso de sus distintos métodos invocándolos por medio de `nltk`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTEO DE TEXTO\n",
    "\n",
    "La librería **NLTK** viene con datos de texto pre-empacados.\n",
    "\n",
    "#### Proyecto Gutenberg\n",
    "<br>\n",
    "<img src=\"./Imagenes/gutenberg_logo.png\" style=\"width:150px;height:150px;\" class=\"center\">\n",
    "<br>\n",
    "\n",
    "El **Proyecto Gutenberg** es un grupo que digitaliza libros de literatura, en su mayoría del dominio público, conteniendo una librería con más de 60,000 libros electrónicos gratuitos en el idioma inglés. Esos documentos son de gran utilidad para practicar los métodos de **NLP**. Se puede consultar toda la información de este proyecto a través de su [sitio web](http://www.gutenberg.org).\n",
    "\n",
    "Para este código se descargarán los archivos del **Proyecto Gutenberg**. Sin embargo, es posible descargar cualquier otro **Corpus** empleando el método `.download()` de la siguiente manera:\n",
    "```python\n",
    "nltk.download()\n",
    "```\n",
    "Una vez ejecutado ese método, se abrirá una nueva ventana mostrando los elementos de **NLTK** que se pueden descargar, estos son `Collections`, `Corpora`, `Models` y `All Packages` permitiendo elegir el directorio de descarga. Para revisar la lista completa de **Corpus** que están disponibles, se puede consultar [esta liga](http://www.nltk.org/nltk_data/). \n",
    "\n",
    "***Nota 1:*** **Corpus**, según el *Diccionario de la Lengua Española*, hace referencia al conjunto lo más extenso y ordenado posible de datos o textos científicos, literarios, etc., que pueden servir de base a una investigación [ver esta referencia](https://dle.rae.es/corpus).\n",
    "\n",
    "El **Corpus** del **Proyecto Gutenberg** incluye 18 libros completos en inglés, los cuales son:\n",
    "\n",
    "* Jane Austen:\n",
    "  * Emma (1816).\n",
    "  * Persuasion (1818).\n",
    "  * Sense and Sensibility (1811).\n",
    "* William Blake:\n",
    "  * Poems (1789).\n",
    "* Thornton W. Burgess:\n",
    "  * The Adventures of Buster Bear (1920).\n",
    "* Sarah Cone Bryant: \n",
    "  * Stories to Tell to Children (1918).\n",
    "* Lewis Carroll:\n",
    "  * Alice's Adventures in Wonderland (1865).\n",
    "* G. K. Chesterton:\n",
    "  * The Man Who Was Thursday (1908).\n",
    "  * The Ball and The Cross (1909).\n",
    "  * The Wisdom of Father Brown (1914).\n",
    "* Maria Edgeworth: \n",
    "  * The Parent's Assistant.\n",
    "* King James:\n",
    "  * The Bible.\n",
    "* Herman Melville:\n",
    "  * Moby Dick (1851).\n",
    "* John Milton: \n",
    "  * Paradise Lost (1667).\n",
    "* William Shakespeare:\n",
    "  * The Tragedie of Julius Caesar (1599).\n",
    "  * The Tragedie of Hamlet (1599).\n",
    "  * The Tragedie of Macbeth (1603).\n",
    "* Walt Whitman: \n",
    "  * Leaves of Grass (1855).\n",
    "\n",
    "Se puede descargar directamente el **Corpus** del **Proyecto Gutenberg** de la manera descrita a continuación, verificando los identificadores de su contenido por medio del método `.corpus.gutenberg.fileids()`.\n",
    "\n",
    "***Nota 2:*** Para el método `.corpus.gutenberg.fileids()`, la palabra correspondiente al nombre del **Corpus** cambia según sea el que se esté utilizando.\n",
    "\n",
    "***Nota 3:*** Los datos se descargarán en las siguientes ubicaciones:\n",
    "* Windows: `C:\\nltk_data`\n",
    "* MacOS: `/Users/user/nltk_data`\n",
    "* Linux: `/usr/share/nltk_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/Villalon/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importación de la librería NLTK\n",
    "import nltk\n",
    "\n",
    "#Descarga del Corpus Gutenberg\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "#Revisar los identificadores del Corpus\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizará la lectura de uno de los textos, será el libro **Moby Dick** de ***Herman Melville***. \n",
    "\n",
    "Para ello se empleará el método `.corpus.gutenberg.words()` y se asignará a la variable `md` para darle un nombre corto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El contenido del libro es:\n",
      " ['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', ...]\n"
     ]
    }
   ],
   "source": [
    "#Lectura de un texto\n",
    "md = nltk.corpus.gutenberg.words(\"melville-moby_dick.txt\")\n",
    "\n",
    "#Impresión de los Resultados\n",
    "print(\"El contenido del libro es:\\n\", md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede acceder a las palabras contenidas en el documento como elementos de una lista empleando corchetes. \n",
    "\n",
    "***Nota:*** Los espacios no son considerados pero los signos de puntuación y caracteres especiales si cuentan. Por lo mismo, los términos *palabra* y *elemento* hacen referencia a lo mismo en este **Tema**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El primer elemento del documento es: [\n",
      "Los primeros 8 elementos del documento son: ['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']']\n",
      "Los elementos 31 a 35 del documento son: ['heart', ',', 'body', ',', 'and']\n"
     ]
    }
   ],
   "source": [
    "#Elementos en el texto\n",
    "print(\"El primer elemento del documento es:\", md[0])\n",
    "print(\"Los primeros 8 elementos del documento son:\", md[:8])\n",
    "print(\"Los elementos 31 a 35 del documento son:\", md[30:35])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, es posible contar la cantidad de veces que una palabra aparece en el documento empleando el método `.count()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de veces que aparece la palabra \"whale\" es: 906 veces\n",
      "La cantidad de veces que aparece la palabra \"Ahab\" es: 501 veces\n",
      "La cantidad de veces que aparece la palabra \"boat\" es: 330 veces\n",
      "La cantidad de veces que aparece la palabra \"laptop\" es: 0 veces\n"
     ]
    }
   ],
   "source": [
    "#Conteo de la cantidad de veces que aparece una palabra en el texto\n",
    "print(\"La cantidad de veces que aparece la palabra \\\"whale\\\" es:\", md.count(\"whale\"), \"veces\")\n",
    "print(\"La cantidad de veces que aparece la palabra \\\"Ahab\\\" es:\", md.count(\"Ahab\"), \"veces\")\n",
    "print(\"La cantidad de veces que aparece la palabra \\\"boat\\\" es:\", md.count(\"boat\"), \"veces\")\n",
    "print(\"La cantidad de veces que aparece la palabra \\\"laptop\\\" es:\", md.count(\"laptop\"), \"veces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede realizar el conteo de los elementos contenidos en el documento a través del método `.len()`. De esa manera, es posible imprimir los últimos elementos en el mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de elementos en el documento es: 260819\n",
      "Los últimos 5 elementos del documento son: ['only', 'found', 'another', 'orphan', '.']\n"
     ]
    }
   ],
   "source": [
    "#Conteo de la cantidad de elementos en el texto\n",
    "print(\"La cantidad de elementos en el documento es:\", len(md))\n",
    "print(\"Los últimos 5 elementos del documento son:\", md[len(md)-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, es posible identificar la cantidad de palabras únicas que existen en el documento a través del método `.set()`, el cual genera una lista que contiene la cantidad de palabras únicas en el documento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de palabras únicas en el documento es: 19317\n"
     ]
    }
   ],
   "source": [
    "#Conteo de la cantidad de palabras únicas en el texto\n",
    "md_set = set(md)\n",
    "\n",
    "#Impresión de los Resultados\n",
    "print(\"La cantidad de palabras únicas en el documento es:\", len(md_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular el número promedio de veces que una palabra única aparece en el texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad promedio de veces que una palabra única aparece en el texto es: 13.50\n"
     ]
    }
   ],
   "source": [
    "#Promedio de veces que una palabra única aparece en el texto\n",
    "prom = len(md) / len(md_set)\n",
    "\n",
    "#Impresión de los Resultados\n",
    "print(\"La cantidad promedio de veces que una palabra única aparece en el texto es: %.2f\"% prom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>.: Fin del Subtema :.</b>\n",
    "</div>\n",
    "\n",
    "***Liga de aceso al siguiente Subtema:*** \n",
    "<br>[b. Conteo de Palabras por Enunciado](b.%20Conteo%20de%20Palabras%20por%20Enunciado.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
