{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<img src=\"./Imagenes/ITESO_Logo.png\" style=\"width:500px;height:142px;\" title=\"Logo ITESO\">\n",
    "<br><font face = \"Times New Roman\" size = \"6\"><b><center>Maestría en Sistemas Computacionales</center></b></font>\n",
    "<br><font face = \"Times New Roman\" size = \"5\"><b><center>Programación para Análisis de Datos</center></b></font>\n",
    "\n",
    "<b><br><font face = \"Times New Roman\" size = \"4\"><center>Unidad 5: Proceso de Selección de Métodos</center></font>\n",
    "<font face = \"Times New Roman\" size = \"4\"><center>Tema 5.1: Procesamiento de Lenguaje Natural</center></font>\n",
    "<font face = \"Times New Roman\" size = \"4\"><center>Subtema d: Palabras Informativas</center></font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PALABRAS INFORMATIVAS\n",
    "\n",
    "Para este ejemplo se empleará nuevamente el **Corpus** `Gutenberg`, del cual se leerán los datos del libro **Alice's Adventures in Wonderland** de ***Lewis Carroll*** y se determinará su **Distribución de Frecuencia** en un **Diccionario** como se revisó previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de la librería NLTK\n",
    "import nltk\n",
    "\n",
    "#Lectura de un texto\n",
    "alice = nltk.corpus.gutenberg.words(\"carroll-alice.txt\")\n",
    "\n",
    "#Creación del diccionario con la distribución de frecuencias\n",
    "alice_fd = nltk.FreqDist(alice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se buscan las 100 palabras más empleadas, y se asignan a una lista empleando el método `.most_common()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Distribución de Frecuencia es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 1993),\n",
       " (\"'\", 1731),\n",
       " ('the', 1527),\n",
       " ('and', 802),\n",
       " ('.', 764),\n",
       " ('to', 725),\n",
       " ('a', 615),\n",
       " ('I', 543),\n",
       " ('it', 527),\n",
       " ('she', 509),\n",
       " ('of', 500),\n",
       " ('said', 456),\n",
       " (\",'\", 397),\n",
       " ('Alice', 396),\n",
       " ('in', 357),\n",
       " ('was', 352),\n",
       " ('you', 345),\n",
       " (\"!'\", 278),\n",
       " ('that', 275),\n",
       " ('as', 246),\n",
       " ('her', 243),\n",
       " (':', 216),\n",
       " ('t', 216),\n",
       " ('at', 202),\n",
       " ('s', 195),\n",
       " ('on', 189),\n",
       " (\".'\", 187),\n",
       " (';', 186),\n",
       " ('had', 177),\n",
       " ('with', 175),\n",
       " ('all', 173),\n",
       " ('!', 155),\n",
       " (\"?'\", 154),\n",
       " ('be', 145),\n",
       " ('-', 141),\n",
       " ('for', 140),\n",
       " ('--', 140),\n",
       " ('but', 133),\n",
       " ('not', 129),\n",
       " ('they', 129),\n",
       " ('very', 126),\n",
       " ('little', 125),\n",
       " ('so', 124),\n",
       " ('out', 116),\n",
       " ('this', 113),\n",
       " ('The', 108),\n",
       " ('he', 101),\n",
       " ('down', 99),\n",
       " ('up', 98),\n",
       " ('is', 97),\n",
       " ('about', 94),\n",
       " ('one', 94),\n",
       " ('his', 94),\n",
       " ('what', 93),\n",
       " ('them', 88),\n",
       " ('know', 87),\n",
       " ('were', 85),\n",
       " ('like', 84),\n",
       " ('went', 83),\n",
       " ('again', 83),\n",
       " ('herself', 83),\n",
       " ('if', 78),\n",
       " ('or', 76),\n",
       " ('thought', 74),\n",
       " ('Queen', 74),\n",
       " ('could', 73),\n",
       " ('have', 73),\n",
       " ('then', 72),\n",
       " ('would', 70),\n",
       " ('no', 69),\n",
       " ('when', 69),\n",
       " ('do', 68),\n",
       " ('time', 68),\n",
       " ('into', 67),\n",
       " ('And', 67),\n",
       " ('see', 66),\n",
       " ('there', 65),\n",
       " ('It', 64),\n",
       " ('off', 62),\n",
       " ('me', 61),\n",
       " ('King', 61),\n",
       " ('did', 60),\n",
       " ('*', 60),\n",
       " ('Turtle', 59),\n",
       " ('began', 58),\n",
       " ('m', 58),\n",
       " ('can', 57),\n",
       " ('way', 56),\n",
       " ('ll', 56),\n",
       " ('its', 56),\n",
       " ('Mock', 56),\n",
       " ('by', 55),\n",
       " ('my', 55),\n",
       " ('Hatter', 55),\n",
       " ('Gryphon', 55),\n",
       " ('quite', 53),\n",
       " ('your', 53),\n",
       " ('an', 52),\n",
       " ('much', 51),\n",
       " ('say', 51)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Búsqueda de las 100 palabras más empleadas en el diccionario\n",
    "alice_fd_100 = alice_fd.most_common(100)\n",
    "\n",
    "#Impresión de los Resultados\n",
    "print(\"La Distribución de Frecuencia es:\")\n",
    "display(alice_fd_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizan las mismas operaciones para el libro **Moby Dick** de ***Herman Melville*** del mismo **Corpus** `Gutenberg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Distribución de Frecuencia es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 18713),\n",
       " ('the', 13721),\n",
       " ('.', 6862),\n",
       " ('of', 6536),\n",
       " ('and', 6024),\n",
       " ('a', 4569),\n",
       " ('to', 4542),\n",
       " (';', 4072),\n",
       " ('in', 3916),\n",
       " ('that', 2982),\n",
       " (\"'\", 2684),\n",
       " ('-', 2552),\n",
       " ('his', 2459),\n",
       " ('it', 2209),\n",
       " ('I', 2124),\n",
       " ('s', 1739),\n",
       " ('is', 1695),\n",
       " ('he', 1661),\n",
       " ('with', 1659),\n",
       " ('was', 1632),\n",
       " ('as', 1620),\n",
       " ('\"', 1478),\n",
       " ('all', 1462),\n",
       " ('for', 1414),\n",
       " ('this', 1280),\n",
       " ('!', 1269),\n",
       " ('at', 1231),\n",
       " ('by', 1137),\n",
       " ('but', 1113),\n",
       " ('not', 1103),\n",
       " ('--', 1070),\n",
       " ('him', 1058),\n",
       " ('from', 1052),\n",
       " ('be', 1030),\n",
       " ('on', 1005),\n",
       " ('so', 918),\n",
       " ('whale', 906),\n",
       " ('one', 889),\n",
       " ('you', 841),\n",
       " ('had', 767),\n",
       " ('have', 760),\n",
       " ('there', 715),\n",
       " ('But', 705),\n",
       " ('or', 697),\n",
       " ('were', 680),\n",
       " ('now', 646),\n",
       " ('which', 640),\n",
       " ('?', 637),\n",
       " ('me', 627),\n",
       " ('like', 624),\n",
       " ('The', 612),\n",
       " ('their', 612),\n",
       " ('are', 586),\n",
       " ('they', 586),\n",
       " ('an', 582),\n",
       " ('some', 578),\n",
       " ('then', 571),\n",
       " ('my', 564),\n",
       " ('when', 553),\n",
       " ('upon', 538),\n",
       " ('out', 529),\n",
       " ('into', 520),\n",
       " ('man', 508),\n",
       " ('ship', 507),\n",
       " ('up', 505),\n",
       " ('more', 501),\n",
       " ('Ahab', 501),\n",
       " ('.\"', 489),\n",
       " ('no', 484),\n",
       " ('them', 471),\n",
       " ('ye', 460),\n",
       " ('what', 442),\n",
       " ('old', 436),\n",
       " ('sea', 433),\n",
       " ('would', 421),\n",
       " ('if', 421),\n",
       " ('been', 415),\n",
       " ('we', 413),\n",
       " ('other', 412),\n",
       " ('over', 403),\n",
       " ('these', 381),\n",
       " ('will', 379),\n",
       " ('its', 372),\n",
       " ('And', 369),\n",
       " ('down', 364),\n",
       " ('only', 360),\n",
       " ('such', 336),\n",
       " ('head', 335),\n",
       " ('though', 335),\n",
       " ('boat', 330),\n",
       " ('her', 329),\n",
       " ('time', 324),\n",
       " ('any', 320),\n",
       " ('who', 319),\n",
       " ('long', 318),\n",
       " ('very', 311),\n",
       " ('It', 310),\n",
       " ('than', 309),\n",
       " ('!\"', 305),\n",
       " ('about', 304)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lectura de un texto\n",
    "moby = nltk.corpus.gutenberg.words(\"melville-moby_dick.txt\")\n",
    "\n",
    "#Creación del diccionario con la distribución de frecuencias\n",
    "moby_fd = nltk.FreqDist(moby)\n",
    "\n",
    "#Búsqueda de las 100 palabras más empleadas en el diccionario\n",
    "moby_fd_100 = moby_fd.most_common(100)\n",
    "\n",
    "#Impresión de los Resultados\n",
    "print(\"La Distribución de Frecuencia es:\")\n",
    "display(moby_fd_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que ya se cuenta con las 100 palabras más empleadas en cada uno de los dos libros, no será necesario tener la cantidad de veces que se repite cada una de ellas. Es por ello que se eliminará este dato, para que solamente reste la lista de los 100 elementos más empleados en cada libro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las palabras más utilizadas en \"Alice\" son:\n",
      " [',', \"'\", 'the', 'and', '.', 'to', 'a', 'I', 'it', 'she', 'of', 'said', \",'\", 'Alice', 'in', 'was', 'you', \"!'\", 'that', 'as', 'her', ':', 't', 'at', 's', 'on', \".'\", ';', 'had', 'with', 'all', '!', \"?'\", 'be', '-', 'for', '--', 'but', 'not', 'they', 'very', 'little', 'so', 'out', 'this', 'The', 'he', 'down', 'up', 'is', 'about', 'one', 'his', 'what', 'them', 'know', 'were', 'like', 'went', 'again', 'herself', 'if', 'or', 'thought', 'Queen', 'could', 'have', 'then', 'would', 'no', 'when', 'do', 'time', 'into', 'And', 'see', 'there', 'It', 'off', 'me', 'King', 'did', '*', 'Turtle', 'began', 'm', 'can', 'way', 'll', 'its', 'Mock', 'by', 'my', 'Hatter', 'Gryphon', 'quite', 'your', 'an', 'much', 'say']\n",
      "\n",
      "Las palabras más utilizadas en \"Moby Dick\" son:\n",
      " [',', 'the', '.', 'of', 'and', 'a', 'to', ';', 'in', 'that', \"'\", '-', 'his', 'it', 'I', 's', 'is', 'he', 'with', 'was', 'as', '\"', 'all', 'for', 'this', '!', 'at', 'by', 'but', 'not', '--', 'him', 'from', 'be', 'on', 'so', 'whale', 'one', 'you', 'had', 'have', 'there', 'But', 'or', 'were', 'now', 'which', '?', 'me', 'like', 'The', 'their', 'are', 'they', 'an', 'some', 'then', 'my', 'when', 'upon', 'out', 'into', 'man', 'ship', 'up', 'more', 'Ahab', '.\"', 'no', 'them', 'ye', 'what', 'old', 'sea', 'would', 'if', 'been', 'we', 'other', 'over', 'these', 'will', 'its', 'And', 'down', 'only', 'such', 'head', 'though', 'boat', 'her', 'time', 'any', 'who', 'long', 'very', 'It', 'than', '!\"', 'about']\n"
     ]
    }
   ],
   "source": [
    "#Eliminación de las repeticiones\n",
    "alice_100  = [elemento[0] for elemento in alice_fd_100]\n",
    "moby_100 = [elemento[0] for elemento in moby_fd_100]\n",
    "\n",
    "#Impresión de los Resultados\n",
    "print(\"Las palabras más utilizadas en \\\"Alice\\\" son:\\n\", alice_100)\n",
    "print(\"\\nLas palabras más utilizadas en \\\"Moby Dick\\\" son:\\n\", moby_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambas listas de palabras pueden ser restadas una de la otra, lo cual dejará solamente la diferencia entre ellas. Esto es, las palabras que se usan en un libro y que no aparecen en el otro. Para ello se emplea el método `.set()` el cual genera una nueva lista.\n",
    "\n",
    "Al eliminar las palabras contenidas en la lista `moby_100` de la lista `alice_100`, como resultado se genera una lista que contiene las palabras únicas que están contenidas en **Alice's Adventures in Wonderland**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las palabras únicas en \"Alice\" son:\n",
      " ['Alice', 'did', 't', \".'\", 'Gryphon', 'quite', 'again', \",'\", ':', 'see', 'much', 'm', 'said', 'little', \"!'\", 'can', 'Queen', 'began', 'thought', 'll', 'way', 'King', \"?'\", '*', 'Turtle', 'do', 'she', 'know', 'Mock', 'went', 'off', 'your', 'Hatter', 'could', 'herself', 'say']\n"
     ]
    }
   ],
   "source": [
    "#Determinación de Palabras Únicas\n",
    "alice_uni = list(set(alice_100) - set(moby_100))\n",
    "\n",
    "#Impresión de los Resultados\n",
    "print(\"Las palabras únicas en \\\"Alice\\\" son:\\n\", alice_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera similar, al eliminar las palabras contenidas en la lista `alice_100` de la lista `moby_100`, como resultado se genera una lista que contiene las palabras únicas que están contenidas en **Moby Dick**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las palabras únicas en \"Moby Dick\" son:\n",
      " ['!\"', 'other', 'him', 'from', 'are', 'boat', 'some', 'sea', 'who', 'their', 'But', 'ye', 'man', 'head', 'upon', 'more', 'ship', 'over', 'Ahab', 'now', '?', 'we', 'old', 'these', '.\"', 'though', 'any', '\"', 'been', 'only', 'long', 'such', 'which', 'than', 'whale', 'will']\n"
     ]
    }
   ],
   "source": [
    "#Determinación de Palabras Únicas\n",
    "moby_uni = list(set(moby_100) - set(alice_100))\n",
    "\n",
    "#Impresión de los Resultados\n",
    "print(\"Las palabras únicas en \\\"Moby Dick\\\" son:\\n\", moby_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>.: Fin del Subtema :.</b>\n",
    "</div>\n",
    "\n",
    "***Liga de aceso al siguiente Subtema:*** \n",
    "<br>[e. Bigramas](e.%20Bigramas.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
