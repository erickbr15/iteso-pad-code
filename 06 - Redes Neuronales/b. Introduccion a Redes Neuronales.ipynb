{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<img src=\"./Imagenes/ITESO_Logo.png\" style=\"width:500px;height:142px;\" title=\"Logo ITESO\">\n",
    "<br><font face = \"Times New Roman\" size = \"6\"><b><center>Maestría en Sistemas Computacionales</center></b></font>\n",
    "<br><font face = \"Times New Roman\" size = \"5\"><b><center>Programación para Análisis de Datos</center></b></font>\n",
    "\n",
    "<b><br><font face = \"Times New Roman\" size = \"4\"><center>Unidad 5: Proceso de Selección de Métodos</center></font>\n",
    "<font face = \"Times New Roman\" size = \"4\"><center>Tema 5.2: Redes Neuronales</center></font>\n",
    "<font face = \"Times New Roman\" size = \"4\"><center>Subtema b: Introducción a Redes Neuronales</center></font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCCIÓN A REDES NEURONALES \n",
    "\n",
    "### El Perceptrón\n",
    "Un **Perceptrón** es el bloque de construcción de las **Redes Neuronales (Neural Networks, NN)**, así como de los modelos de **Aprendizaje Profundo (Deep Learning)** ya que son formalizados como un conjunto de estos bloques agrupados. Es por ello que para poder comprender las ***NN***, es necesario estudiar el concepto del **Perceptrón**.\n",
    "\n",
    "Un **Perceptrón** toma una entrada, lo multiplica por un valor (peso) y regresa un valor *1* solo si el valor agregado es mayor que un valor límite (*threshold*) previamente definido, en caso contrario regresa un *0*.\n",
    "\n",
    "Una manera de comprender mejor al **Perceptrón** es verlo como un dispositivo que toma una decisión a través de la determinación del peso de una evidencia. A través de la variación de los pesos y el valor límite, es posible obtener distintos modelos para la toma de decisiones.\n",
    "\n",
    "La siguiente figura muestra el concepto del **Perceptrón** para diversas entradas y una sola salida, con las ecuaciones matemáticas correspondientes:\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"./Imagenes/Perceptron.png\" style=\"width:500px;height:254px;\" class=\"center\">\n",
    "<br>\n",
    "<br>\n",
    "#### La función AND empleando un Perceptrón\n",
    "La *tabla de verdad* de la compuerta lógica **AND** que realiza la función booleana de producto lógico, es descrita de la siguiente manera: \n",
    "<br>\n",
    "<img src=\"./Imagenes/AND.png\" style=\"width:140px;height:185px;\" class=\"center\">\n",
    "<br>\n",
    "Haciendo la analogía con un **Perceptrón**,tenemos:\n",
    "<br>\n",
    "<img src=\"./Imagenes/AND_Perceptron.png\" style=\"width:700px;height:179px;\" class=\"center\">\n",
    "<br>\n",
    "Toma dos entradas binarias y proporciona su producto como la salida. \n",
    "\n",
    "Considerando la siguiente tabla, los valores *Input 1* e *Input 2* corresponden a los resultados de la multiplicación de las entradas por los pesos, esto es: <br>\n",
    "> *Input 1* = *v1* * *w1*<br>\n",
    "> *Input 2* = *v2* * *w2*<br>\n",
    "> *threshold* = 2.0<br>\n",
    "\n",
    "La salida generada por el **Perceptrón** será:\n",
    "<br>\n",
    "<img src=\"./Imagenes/AND_Solution.png\" style=\"width:700px;height:108px;\" class=\"center\">\n",
    "<br>\n",
    "#### Función Sigmoidal (Sigmoide Neuron)\n",
    "El problema con el **Perceptrón** es que son funciones escalón muy definidas que sólamente proporcionan salidas iguales a *0* o *1*, donde pequeños cambios en los pesos pueden causar una enorme diferencia en la salida. Sin embargo, la **Función Sigmoidal o Sigmoide** tiene la característica de que pequeños cambios en los pesos solo provocarán pequeños cambios en las salidas.\n",
    "\n",
    "Debido a ello, hay una diferencia entre el **Función Sigmoidal** y el **Perceptrón**, donde en lugar de emplear un valor límite (*threshold*) se emplea la ***Función Matemática Sigmoide*** para obtener la salida de la suma de los pesos ponderados.\n",
    "\n",
    "La ***Función Sigmoide*** y su salida está determinada por:\n",
    "<br>\n",
    "<img src=\"./Imagenes/Sigmoid.png\" style=\"width:400px;height:266px;\" class=\"center\">\n",
    "<br>\n",
    "\n",
    "#### Otras Funciones de Activación\n",
    "A manera de resumen se enumeran seis funciones de activación con su respectiva función matemática: \n",
    "\n",
    "1. **Función Identidad (Identity):**\n",
    "<br>\n",
    "<img src=\"./Imagenes/identity.png\" style=\"width:337px;height:230px;\" class=\"center\">\n",
    "<img src=\"./Imagenes/identity_f.png\" style=\"width:136px;height:50px;\" class=\"center\">\n",
    "<br>\n",
    "2. **Función Paso Binario (Binary Step):**\n",
    "<br>\n",
    "<img src=\"./Imagenes/binary_step.png\" style=\"width:337px;height:230px;\" class=\"center\">\n",
    "<img src=\"./Imagenes/binary_step_f.png\" style=\"width:166px;height:50px;\" class=\"center\">\n",
    "<br>\n",
    "3. **Función Sigmoide (Sigmoid):**\n",
    "<br>\n",
    "<img src=\"./Imagenes/sigmoid2.png\" style=\"width:337px;height:230px;\" class=\"center\">\n",
    "<img src=\"./Imagenes/sigmoid2_f.png\" style=\"width:148px;height:50px;\" class=\"center\">\n",
    "<br>\n",
    "4. **Función de Unidad Lineal Rectificada (Rectified Linear Unit, ReLU):**\n",
    "<br>\n",
    "<img src=\"./Imagenes/relu.png\" style=\"width:337px;height:230px;\" class=\"center\">\n",
    "<img src=\"./Imagenes/relu_f.png\" style=\"width:192px;height:50px;\" class=\"center\">\n",
    "<br>\n",
    "5. **Función SoftPlus:**\n",
    "<br>\n",
    "<img src=\"./Imagenes/softplus.png\" style=\"width:337px;height:230px;\" class=\"center\">\n",
    "<img src=\"./Imagenes/softplus_f.png\" style=\"width:152px;height:50px;\" class=\"center\">\n",
    "<br>\n",
    "6. **Función Gausiana (Gaussian):**\n",
    "<br>\n",
    "<img src=\"./Imagenes/gaussian.png\" style=\"width:337px;height:230px;\" class=\"center\">\n",
    "<img src=\"./Imagenes/gaussian_f.png\" style=\"width:148px;height:50px;\" class=\"center\">\n",
    "<br>\n",
    "\n",
    "### ¿Qué es una Red Neuronal?\n",
    "Una **Red Neuronal (Neural Network, NN)**, también conocida como **Red Neuronal Artificial (Artificial Neural Network, ANN)**, es el bloque básico de construcción en el **Aprendizaje Profundo (Deep Learning)**. Consiste en capas (*layers*) de **Funciones Sigmoidales** como funciones de activación, apiladas juntas para formar una arquitectura mayor. La siguiente figura muestra la estructura básica de una **Red Neuronal**:\n",
    "<br>\n",
    "<img src=\"./Imagenes/Neural_Network.png\" style=\"width:700px;height:381px;\" class=\"center\">\n",
    "<br>\n",
    "Cada círculo de la figura corresponde a un neurón con una función de activación realizada por la **Función Sigmoidal**. Consiste de tres tipos de capas (*layers*), que son la capa de entrada (*input layer*), la capa de salida (*output layer*) y las capas ocultas (*hidden layers*). Todas las capas están completamente conectadas con la siguiente capa, por lo mismo también se le conoce como una **Red Neuronal Completamente Conectada (Fully Conected Neural Network, FCNN)**.\n",
    "\n",
    "Cada neurón tiene sus respectivos valores de pesos (*weights*). La primera capa (*input layer*) toma los datos de la variable independiente como la entrada. La última capa (*output layer*) predice la clase. El número de capas ocultas (*hidden layers*) y el número de neurones en las capas ocultas no es definido, por lo que definir esta cantidad puede ayudar a robustecer los resultados.\n",
    "\n",
    "### ¿Cómo aprende una Red Neuronal?\n",
    "Una **Red Neuronal (Neural Network, NN)** es simplemente la suma ponderada de las entradas. Debido a ello, el proceso de aprendizaje de la red se basa en la actualización de los pesos (*weights*) correspondientes, para ello se requiere de un método. \n",
    "\n",
    "El desempeño (*performance*) de una **Red Neuronal** se refiere al nivel de certeza (asertividad) de las predicciones basadas en las etiquetas reales. El valor de la última capa (*output layer*) se calcula por medio de el cruce de valores a través de toda la **Red Neuronal** y determinando el valor que cada neurón proporciona. Este proceso de realizar operaciones cruzadas a través de la **Red Neuronal** se conoce como **Propagación Hacia Adelante (Forward Propagation)**. La siguiente figura muestra la manera como los datos se relacionan en un proceso de **Forward Propagation** a través de una **Red Neuronal**:\n",
    "<br>\n",
    "<img src=\"./Imagenes/Forward_Prop.png\" style=\"width:700px;height:494px;\" class=\"center\">\n",
    "<br>\n",
    "Para realizar la medición del desempeño (*performance*) de una **Red Neuronal**, se introduce una **Función de Pérdida (Loss Function)** la cual determina lo \"malo\" que se está desempeñando la **Red Neuronal**. Esta **Función de Pérdida** depende del problema que se está tratando de resolver, y existen muchas funciones que cumplen con este cometido, pero se mencionan dos principales: \n",
    "\n",
    "1. **Pérdida de Entropía Cruzada (Cross-Entropy Loss, CEL)**: Se emplea para problemas de clasificación, realiza el cálculo de un valor empleando una función que está basada en la etiqueta de la entrada verdadera y la etiqueta del valor de salida predecido. La función está definida de la siguiente manera, donde *y* es la etiqueta verdadera (entrada) y *p* es la etiqueta predecida (salida):\n",
    "\n",
    "        CEL = −(y*log(p)+(1−y)*log(1−p))\n",
    "\n",
    "2. **Error Medio Cuadrático (Mean Squared Error, MSE)**: Se emplea para problemas de regresión, realiza el cálculo de la distancia entre el valor real y el valor predecido. Está definido de la siguiente manera\n",
    "<br>\n",
    "<img src=\"./Imagenes/MSE.png\" style=\"width:250px;height:129px;\" class=\"center\">\n",
    "<br>\n",
    "\n",
    "Una vez que la pérdida es calculada, se requiere un método que cambie los pesos (*weights*) de la **Red Neuronal** respecto al valor de la pérdida. Para ello, se realiza la **Propagación Hacia Atrás (Back Propagation)** a través de la **Red Neuronal** actualizando los pesos (*weights*), basado en la contribución relativa que cada neurón proporcionó a la salida original. \n",
    "\n",
    "Este proceso se repite, capa por capa, hasta que todos los neurones en la **Red Neuronal** han recibido una señal de pérdida que describe su contribución relativa a la pérdida total. El cambio que se realiza a los pesos (*weights*) se determina por medio del método de **Gradiente Descendiente (Gradient Descent)**, el cual es un concepto de suma importancia para comprender una **Red Neuronal**, es por ello que para mayor información al respecto se puede ver [este video](https://www.youtube.com/watch?v=IHZwWFHWa-w&t=682s) que proporciona mayores detalles.\n",
    "\n",
    "El proceso completo del aprendizaje de la **Red Neuronal** se resume como:\n",
    "<br>\n",
    "<img src=\"./Imagenes/NN_Gradient_Descent.png\" style=\"width:800px;height:282px;\" class=\"center\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>.: Fin del Subtema :.</b>\n",
    "</div>\n",
    "\n",
    "***Liga de aceso al siguiente Subtema:*** \n",
    "<br>[c. Instalación de Keras](c.%20Instalacion%20de%20Keras.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
